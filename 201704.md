# 2017-04-19
 - 使用crawler parse plugin生成饿了么解析job。
 > + 了解spark里，RDD的API里所引用的所有对象，都必须是可序列化的，因为RDD分布在多台机器是，代码和所引用的对象会序列化，然后复制到多台机器，所以凡是被引用的数据，都必须是可序列化的。插件使用到了flatmap参数没有序列化，所以抽取成静态全局变量来解决
 - 继续看thinking in java, 复习java基础知识
 - 根据公司Crane的wiki 衍生学习了java nio, netty 等知识

# 2017-04-20
 - 学习java的日志系统，学习log4j的结构和使用,slf4j作为框架接口
 - 继续复习java语法相关的知识
 - 开会学习了自动化抽取和信息对齐的一些相关知识

# 2017-04-21
 - 学习了docker相关的知识和历史发展
 - 继续看hulk相关的技术文档
